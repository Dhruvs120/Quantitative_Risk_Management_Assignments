{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc2ba2c",
   "metadata": {},
   "source": [
    "### Initial package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import scipy.optimize as opt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import sys, re\n",
    "from statsmodels.distributions.copula.api import CopulaDistribution, GumbelCopula, ClaytonCopula, IndependenceCopula\n",
    "from scipy.stats import norm, t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ed6f9",
   "metadata": {},
   "source": [
    "# Validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asset_df = pd.read_csv('Data/a3/Data_assignment3.csv', sep=';')\n",
    "asset_df.set_index('Date', inplace=True)\n",
    "asset_df = asset_df.loc['04/01/2012':]\n",
    "\n",
    "currency_df = asset_df[['EUR/USD', 'EUR/JPY']]\n",
    "#drop na\n",
    "currency_df.dropna(inplace=True)\n",
    "asset_df.dropna(inplace=True)\n",
    "display(currency_df.tail())\n",
    "display(asset_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create log returns of all columns\n",
    "currency_df['EUR/USD'] = np.log(currency_df['EUR/USD'] / currency_df['EUR/USD'].shift(1))\n",
    "currency_df['EUR/JPY'] = np.log(currency_df['EUR/JPY'] / currency_df['EUR/JPY'].shift(1))\n",
    "\n",
    "#create log returns for all assets in asset_df\n",
    "asset_df['R_S&P500'] = np.log(asset_df['S&P500'] / asset_df['S&P500'].shift(1))\n",
    "asset_df['R_Dax40'] = np.log(asset_df['Dax40'] / asset_df['Dax40'].shift(1))\n",
    "asset_df['R_Nikkei'] = np.log(asset_df['Nikkei'] / asset_df['Nikkei'].shift(1))\n",
    "asset_df['R_Boeing'] = np.log(asset_df['Boeing'] / asset_df['Boeing'].shift(1))\n",
    "asset_df['R_Airbus'] = np.log(asset_df['Airbus'] / asset_df['Airbus'].shift(1))\n",
    "asset_df['R_Volkswagen'] = np.log(asset_df['Volkswagen'] / asset_df['Volkswagen'].shift(1))\n",
    "asset_df['R_ASML'] = np.log(asset_df['ASML'] / asset_df['ASML'].shift(1))\n",
    "asset_df['R_NVIDIA'] = np.log(asset_df['NVIDIA'] / asset_df['NVIDIA'].shift(1))\n",
    "asset_df['R_Stellantis'] = np.log(asset_df['Stellantis'] / asset_df['Stellantis'].shift(1))\n",
    "\n",
    "display(asset_df.head())\n",
    "asset_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "display(currency_df.head())\n",
    "currency_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrected returns to EURO\n",
    "asset_df['C_S&P500'] = (1 + asset_df['R_S&P500']) * (1 + currency_df['EUR/USD']) - 1\n",
    "asset_df['C_Nikkei'] = (1 + asset_df['R_Nikkei']) * (1 + currency_df['EUR/JPY']) - 1 \n",
    "asset_df['C_Dax40'] = asset_df['R_Dax40']\n",
    "asset_df['C_Boeing'] = (1 + asset_df['R_Boeing']) * (1 + currency_df['EUR/USD']) - 1\n",
    "asset_df['C_Airbus'] = asset_df['R_Airbus']\n",
    "asset_df['C_Volkswagen'] = asset_df['R_Volkswagen']\n",
    "asset_df['C_ASML'] = asset_df['R_ASML']\n",
    "asset_df['C_NVIDIA'] = (1 + asset_df['R_NVIDIA']) * (1 + currency_df['EUR/USD']) - 1\n",
    "asset_df['C_Stellantis'] = asset_df['R_Stellantis']\n",
    "asset_df.dropna(inplace=True)\n",
    "display(asset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df = pd.read_csv('Data/a1/ECB_Data_10yr_Treasury_bond.csv', sep=',')\n",
    "bond_df.drop('TIME PERIOD', axis=1, inplace=True)\n",
    "bond_df['Date'] = pd.to_datetime(bond_df['Date'], format='%Y-%m-%d')\n",
    "#now change the format to dd/mm/yyyy\n",
    "bond_df['Date'] = bond_df['Date'].dt.strftime('%d/%m/%Y')\n",
    "bond_df.set_index('Date', inplace=True)\n",
    "bond_df = bond_df.loc['05/01/2012':]  # Use consistent date format\n",
    "bond_df = bond_df.rename(columns={'Yield curve spot rate, 10-year maturity - Government bond': 'Bond_Yield'})\n",
    "asset_df = pd.merge(asset_df, bond_df, left_index=True, right_index=True, how='left')\n",
    "display(asset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c172e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Add a column for the interest bond value per day\n",
    "days_per_annum = 365\n",
    "interest_bond = 1500000\n",
    "\n",
    "# Initialize the arrays with appropriate lengths matching the DataFrame\n",
    "daily_rates = np.zeros(len(asset_df))\n",
    "\n",
    "# Set initial value\n",
    "\n",
    "# Calculate bond values day by day based on the daily yield rate\n",
    "for i in range(len(asset_df)):\n",
    "    # Adding 1.5% to account for the credit risk spread\n",
    "    daily_rate = (((asset_df['Bond_Yield'].iloc[i] + 1.5) / (days_per_annum)) * (7/5)) / 100\n",
    "    daily_rates[i] = daily_rate\n",
    "# Add vectors to the dataframe\n",
    "asset_df['Interest_Bond_daily_rate'] = daily_rates\n",
    "display(asset_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fc2cb",
   "metadata": {},
   "source": [
    "# Copulas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834ce1e",
   "metadata": {},
   "source": [
    "For the return pairs we have chosen the following:\n",
    "\n",
    "- Boeing and Airbus\n",
    "- ASML and NVIDIA\n",
    "- Volkswagen and Stellantis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd3e01",
   "metadata": {},
   "source": [
    "### Fit appropriate marginal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in ['C_Volkswagen', 'C_Stellantis', 'C_Airbus', 'C_Boeing', 'C_NVIDIA', 'C_ASML']:\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    plt.suptitle(f'QQ Plots and KS-test for {asset}', fontsize=16, y=1.02)\n",
    "    \n",
    "    data = asset_df[asset]\n",
    "\n",
    "    distributions = [\n",
    "        (st.norm, 'Normal Distribution', ()),\n",
    "        (st.t, 'Student-t (3 df)', (3,)),\n",
    "        (st.t, 'Student-t (4 df)', (4,)),\n",
    "        (st.t, 'Student-t (5 df)', (5,)),\n",
    "        (st.t, 'Student-t (6 df)', (6,)),\n",
    "        (st.gumbel_r, 'Gumbel Distribution', ()),\n",
    "        (st.genpareto, 'GenPareto (Clayton approx)', ())\n",
    "    ]\n",
    "    \n",
    "    for idx, (dist, title, shape_param) in enumerate(distributions, 1):\n",
    "        ax = plt.subplot(3, 3, idx)\n",
    "\n",
    "        if shape_param:\n",
    "            loc, scale = st.t.fit(data, f0=shape_param[0])[1:]\n",
    "            sparams = (shape_param[0], loc, scale)\n",
    "        else:\n",
    "            params = dist.fit(data)\n",
    "            sparams = params\n",
    "\n",
    "        ks_stat, p_value = st.kstest(data, dist.name, args=sparams)\n",
    "\n",
    "        st.probplot(data, dist=dist, sparams=sparams, plot=plt)\n",
    "        plt.title(title, pad=10)\n",
    "\n",
    "        text = f'KS stat: {ks_stat:.4f}\\np-value: {p_value:.4f}'\n",
    "        plt.text(0.98, 0.02, text, transform=ax.transAxes,\n",
    "                 verticalalignment='bottom', horizontalalignment='right',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20114d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create seperate dataframes for each couples with date and closing prices \n",
    "df_pair1 = asset_df[['C_Volkswagen','C_Stellantis']]*100\n",
    "df_pair2 = asset_df[['C_Airbus','C_Boeing']]*100\n",
    "df_pair3 = asset_df[['C_NVIDIA','C_ASML']]*100\n",
    "\n",
    "display(df_pair1.head())\n",
    "display(df_pair2.head())\n",
    "display(df_pair3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7d913",
   "metadata": {},
   "source": [
    "# Code Bos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f89ae",
   "metadata": {},
   "source": [
    "## grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d44de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "grad.py\n",
    "\n",
    "Purpose:\n",
    "    contain a series of routines used in the\n",
    "      Principles of Programming for Econometrics\n",
    "    course at VU/TI Amsterdam\n",
    "\n",
    "Version:\n",
    "    1       Extract from ppectr.py, excluding GetCovML()\n",
    "\n",
    "Date:\n",
    "    2017/8/21\n",
    "\n",
    "Author:\n",
    "    Charles Bos, based partially on Kevin Sheppard's hessian_2sided, with\n",
    "      ideas/constants from Jurgen Doornik\n",
    "\"\"\"\n",
    "###########################################################\n",
    "\n",
    "###########################################################\n",
    "### vh= _gh_stepsize(vP)\n",
    "def _gh_stepsize(vP, second= False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate stepsize close (but not too close) to machine precision\n",
    "\n",
    "    Inputs:\n",
    "        vP      1D array of parameters\n",
    "\n",
    "    Return value:\n",
    "        vh      1D array of step sizes\n",
    "    \"\"\"\n",
    "    vh = 1e-8*(np.fabs(vP)+1e-8)   # Find stepsize\n",
    "    dRice= 1e-4 if second else 5e-6  # Let stepsize depend on first/second derivatives\n",
    "    vh= np.maximum(vh, dRice)        # Don't go too small\n",
    "\n",
    "    return vh\n",
    "\n",
    "###########################################################\n",
    "### vG= gradient_2sided(fun, vP, *args)\n",
    "def gradient_2sided(fun, vP, *args):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Compute numerical gradient, using a 2-sided numerical difference\n",
    "\n",
    "    Author:\n",
    "      Charles Bos, following Kevin Sheppard's hessian_2sided, with\n",
    "      ideas/constants from Jurgen Doornik's Num1Derivative\n",
    "\n",
    "    Inputs:\n",
    "      fun     function, as used for minimize()\n",
    "      vP      1D array of size iP of optimal parameters\n",
    "      args    (optional) extra arguments\n",
    "\n",
    "    Return value:\n",
    "      vG      iP vector with gradient\n",
    "\n",
    "    See also:\n",
    "      scipy.optimize.approx_fprime, for forward difference\n",
    "    \"\"\"\n",
    "    iP = np.size(vP)\n",
    "    vP= np.array(vP).reshape(iP)      # Ensure vP is 1D-array\n",
    "\n",
    "    # f = fun(vP, *args)    # central function value is not needed\n",
    "    vh= _gh_stepsize(vP)\n",
    "    mh = np.diag(vh)        # Build a diagonal matrix out of h\n",
    "\n",
    "    fp = np.zeros(iP)\n",
    "    fm = np.zeros(iP)\n",
    "    for i in range(iP):     # Find f(x+h), f(x-h)\n",
    "        fp[i] = fun(vP+mh[i], *args)\n",
    "        fm[i] = fun(vP-mh[i], *args)\n",
    "\n",
    "    vhr = (vP + vh) - vP    # Check for effective stepsize right\n",
    "    vhl = vP - (vP - vh)    # Check for effective stepsize left\n",
    "    vG= (fp - fm) / (vhr + vhl)  # Get central gradient\n",
    "\n",
    "    return vG\n",
    "\n",
    "###########################################################\n",
    "### mG= jacobian_2sided(fun, vP, *args)\n",
    "def jacobian_2sided(fun, vP, *args):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Compute numerical jacobian, using a 2-sided numerical difference\n",
    "\n",
    "    Author:\n",
    "      Charles Bos, following Kevin Sheppard's hessian_2sided, with\n",
    "      ideas/constants from Jurgen Doornik's Num1Derivative\n",
    "\n",
    "    Inputs:\n",
    "      fun     function, return 1D array of size iN\n",
    "      vP      1D array of size iP of optimal parameters\n",
    "      args    (optional) extra arguments\n",
    "\n",
    "    Return value:\n",
    "      mG      iN x iP matrix with jacobian\n",
    "\n",
    "    See also:\n",
    "      numdifftools.Jacobian(), for similar output\n",
    "    \"\"\"\n",
    "    iP = np.size(vP)\n",
    "    vP= vP.reshape(iP)      # Ensure vP is 1D-array\n",
    "\n",
    "    vF = fun(vP, *args)     # evaluate function, only to get size\n",
    "    iN= vF.size\n",
    "\n",
    "    vh= _gh_stepsize(vP)\n",
    "    mh = np.diag(vh)        # Build a diagonal matrix out of h\n",
    "\n",
    "    mGp = np.zeros((iN, iP))\n",
    "    mGm = np.zeros((iN, iP))\n",
    "\n",
    "    for i in range(iP):     # Find f(x+h), f(x-h)\n",
    "        mGp[:,i] = fun(vP+mh[i], *args)\n",
    "        mGm[:,i] = fun(vP-mh[i], *args)\n",
    "\n",
    "    vhr = (vP + vh) - vP    # Check for effective stepsize right\n",
    "    vhl = vP - (vP - vh)    # Check for effective stepsize left\n",
    "    mG= (mGp - mGm) / (vhr + vhl)  # Get central jacobian\n",
    "\n",
    "    return mG\n",
    "\n",
    "###########################################################\n",
    "### mH= hessian_2sided(fun, vP, *args)\n",
    "def hessian_2sided(fun, vP, *args):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Compute numerical hessian, using a 2-sided numerical difference\n",
    "\n",
    "    Author:\n",
    "      Kevin Sheppard, adapted by Charles Bos\n",
    "\n",
    "    Source:\n",
    "      https://www.kevinsheppard.com/Python_for_Econometrics\n",
    "\n",
    "    Inputs:\n",
    "      fun     function, as used for minimize()\n",
    "      vP      1D array of size iP of optimal parameters\n",
    "      args    (optional) extra arguments\n",
    "\n",
    "    Return value:\n",
    "      mH      iP x iP matrix with symmetric hessian\n",
    "    \"\"\"\n",
    "    iP = np.size(vP,0)\n",
    "    vP= vP.reshape(iP)    # Ensure vP is 1D-array\n",
    "\n",
    "    f = fun(vP, *args)\n",
    "    vh= _gh_stepsize(vP, second= True)\n",
    "    vPh = vP + vh\n",
    "    vh = vPh - vP\n",
    "\n",
    "    mh = np.diag(vh)            # Build a diagonal matrix out of vh\n",
    "\n",
    "    fp = np.zeros(iP)\n",
    "    fm = np.zeros(iP)\n",
    "    for i in range(iP):\n",
    "        fp[i] = fun(vP+mh[i], *args)\n",
    "        fm[i] = fun(vP-mh[i], *args)\n",
    "\n",
    "    fpp = np.zeros((iP,iP))\n",
    "    fmm = np.zeros((iP,iP))\n",
    "    for i in range(iP):\n",
    "        for j in range(i,iP):\n",
    "            fpp[i,j] = fun(vP + mh[i] + mh[j], *args)\n",
    "            fpp[j,i] = fpp[i,j]\n",
    "            fmm[i,j] = fun(vP - mh[i] - mh[j], *args)\n",
    "            fmm[j,i] = fmm[i,j]\n",
    "\n",
    "    vh = vh.reshape((iP,1))\n",
    "    mhh = vh @ vh.T             # mhh= h h', outer product of h-vector\n",
    "\n",
    "    mH = np.zeros((iP,iP))\n",
    "    for i in range(iP):\n",
    "        for j in range(i,iP):\n",
    "            mH[i,j] = (fpp[i,j] - fp[i] - fp[j] + f + f - fm[i] - fm[j] + fmm[i,j])/mhh[i,j]/2\n",
    "            mH[j,i] = mH[i,j]\n",
    "\n",
    "    return mH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903dec7c",
   "metadata": {},
   "source": [
    "## readarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ba61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "readarg.py\n",
    "\n",
    "Purpose:\n",
    "    contain a series of routines for reading command line arguments\n",
    "\n",
    "Version:\n",
    "    1       Trying things out\n",
    "    2       Allowing for a dictionary\n",
    "    3       Allow for a dictionary argument 'args' which replaces the command line\n",
    "\n",
    "Date:\n",
    "    2018/12/10,\n",
    "\n",
    "Author:\n",
    "    Charles Bos\n",
    "\"\"\"\n",
    "#########################################################\n",
    "### vRes= ReadArg('a', 5, vDef= [1, 2, 3])\n",
    "### ir= ReadArg({'a': [1, 2, 3])\n",
    "### val= ReadArg(2)\n",
    "def ReadArg(sKey, iN= 0, vDef= None, show= False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "       Read the command line argument, returning a single value with whatever was read, or, when used with a dictionary, checking all the keys in the dictionary\n",
    "\n",
    "    Inputs:\n",
    "        sKey        string, label\n",
    "        iN          integer, size and type indication. 0= boolean, 1= scalar, >1= vector, -1= string, <-1 = list of strings\n",
    "        vDef        some type, default value\n",
    "      or\n",
    "        dtArg       dictionary, keys and default values\n",
    "\n",
    "    Outputs:\n",
    "        vRet        vector/list/scalar/boolean. Scalars are of type integer if possible, else float. If label is not found, the default value is returned\n",
    "      or\n",
    "        ir          integer, number of keys read from command line arguments\n",
    "    \"\"\"\n",
    "    if (isinstance(sKey, dict)):\n",
    "        # print ('Going to dict')\n",
    "        return ReadArg_dict(sKey, show= show)\n",
    "\n",
    "    lArg= sys.argv\n",
    "    iA= len(lArg)\n",
    "    iNa= np.fabs(iN)\n",
    "\n",
    "    if (isinstance(sKey, int)):\n",
    "        # val= ReadArg(3);      # Give third command line argument, or None if not found\n",
    "        if (iA-1 > sKey):\n",
    "            return lArg[sKey+1]\n",
    "        return None\n",
    "\n",
    "    if (iN == 0):\n",
    "        vRet= (sKey in lArg)\n",
    "        return vRet\n",
    "\n",
    "\n",
    "    if (not sKey in lArg):\n",
    "        return vDef\n",
    "    j= lArg.index(sKey)+1\n",
    "    vRet= []\n",
    "    bCont= (j < iA)\n",
    "    while bCont:\n",
    "        if (iN > 0):\n",
    "            try:\n",
    "                iElement= float(lArg[j])\n",
    "                vRet.append(iElement)\n",
    "            except ValueError:\n",
    "                print (\"Arg '%s' cannot be converted to float\" % lArg[j])\n",
    "                bCont= False\n",
    "        else:\n",
    "            iElement= lArg[j]\n",
    "            vRet.append(iElement)\n",
    "        j+= 1\n",
    "        bCont= bCont and (len(vRet) < iNa) and (j < iA)\n",
    "\n",
    "    if (iN == 1):\n",
    "        vRet= int(vRet[0]) if ((vRet[0] % 1) == 0) else vRet[0]\n",
    "    elif (iN == -1):\n",
    "        vRet= vRet[0]\n",
    "    elif (iN > 1):\n",
    "        vRet= np.array(vRet).astype(float)\n",
    "    # print (\"Key '\", sKey, \"': \", vRet, sep='')\n",
    "    return vRet\n",
    "\n",
    "#########################################################\n",
    "def ReadArg_float(vArg):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Read through the string elements in vArg, and transform them to floats if possible\n",
    "\n",
    "    Inputs:\n",
    "        vArg    array of length iA, string elements\n",
    "\n",
    "    Return value:\n",
    "        vRet    list, floats of elements of first iR elements which can be translated to floats\n",
    "    \"\"\"\n",
    "    vRet= []\n",
    "    i= 0\n",
    "    iA= len(vArg)\n",
    "    while (i < iA):\n",
    "        try:\n",
    "            dA= float(vArg[i])\n",
    "            vRet.append(dA)\n",
    "            i+= 1\n",
    "        except ValueError:\n",
    "            print (\"Arg '%s' cannot be converted to float\" % vArg[i])\n",
    "            i= iA\n",
    "    return vRet\n",
    "\n",
    "#########################################################\n",
    "def ReadArg_int(vArg):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Read through the string elements in vArg, and transform them to ints if possible\n",
    "\n",
    "    Inputs:\n",
    "        vArg    array of length iA, string elements\n",
    "\n",
    "    Return value:\n",
    "        vRet    list, ints of elements of first iR elements which can be translated to ints\n",
    "    \"\"\"\n",
    "    vRet= []\n",
    "    i= 0\n",
    "    iA= len(vArg)\n",
    "    while (i < iA):\n",
    "        try:\n",
    "            dA= int(vArg[i])\n",
    "            vRet.append(dA)\n",
    "            i+= 1\n",
    "        except ValueError:\n",
    "            print (\"Arg '%s' cannot be converted to int\" % vArg[i])\n",
    "            i= iA\n",
    "    return vRet\n",
    "\n",
    "#########################################################\n",
    "def ReadArg_dict(dtArg, show= False, argv= None):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "       Read the command line argument, filling in the dictionary elements by corresponding elements on the command line.\n",
    "       So\n",
    "            dtArg= {'a': 5, 'b': 'hello', 'c': True, 'd': [5, 6, 3], 'e': ['aa', 'bb', 'cc'], 'f': []}\n",
    "            ir= ReadArg(dtArg)\n",
    "       should read/check for all those keys. When a list is handed over, readarg should check for all elements until the next keyword? If an empty list is passed, same thing, though then by definition strings are read.\n",
    "\n",
    "       Note that the routine is NOT finished probably, possibly the whole concept should be set up differently...\n",
    "\n",
    "    Inputs:\n",
    "        dtArg       dict, with label and value pairs\n",
    "        argv        (optional, for debugging) list of arguments, instead of command line arguments\n",
    "\n",
    "    Outputs:\n",
    "        dtArg       dict, with values adapted as to the command line arguments\n",
    "\n",
    "    Return value:\n",
    "        ir          integer, number of keys found\n",
    "    \"\"\"\n",
    "    lArg= sys.argv if (argv is None) else argv\n",
    "    # dtArg= {'a': 5, 'b': 'hello', 'c': True, 'd': [5, 6, 3], 'e': ['aa', 'bb', 'cc'], 'f': [], 'args': 'exchange Xetra type depth date 2023-07-03 dir /mnt/etf_calc/tmp/2023-07 isin \"IE000JBB8CR7 IE000QDFFK00 IE000SBHVL31 IE000Z8BHG02\" label axa xyt whatever redo', 'isin': ''}\n",
    "    # lArg= ['a', '45', 'hello', 'd', '345', '-2.4', '2.3', 'sdfsf', 'e', 'sdfsa', 'sdfadsfa', 'f', '345', '13', 'df']\n",
    "\n",
    "    if ('args' in dtArg):\n",
    "        # lArg= dtArg['args'].split(' ')        # Incorrect, as it splits quoted strings\n",
    "        # lArg= [p for p in re.split(\"( |\\\\\\\".*?\\\\\\\"|'.*?')\", dtArg['args']) if p.strip()]          # Correct, but a bit convoluted\n",
    "        lArg= re.findall(r'[^\"\\s]\\S*|\".+?\"', dtArg['args'])          # Also correct, simple findall?\n",
    "        print ('Using arguments:', lArg)\n",
    "\n",
    "    asK= list(dtArg.keys())\n",
    "    iK= len(asK)\n",
    "    iL= len(lArg)\n",
    "\n",
    "\n",
    "    sK= None\n",
    "    l0= l1= 0\n",
    "    dtFound= {}\n",
    "    while (l0 < iL):\n",
    "        # print (f'Argument {l0}/{iL}...')\n",
    "        if (lArg[l0] in asK):\n",
    "            sK= lArg[l0]\n",
    "            if isinstance(dtArg[sK], bool):\n",
    "                l1= l0+1\n",
    "                # print (f'{type(dtArg[sK])} {sK} at {l0}-{l1}')\n",
    "            elif isinstance(dtArg[sK], (str, int, float)):\n",
    "                l1= l0+1+1\n",
    "                # print (f'{type(dtArg[sK])} {sK} at {l0}-{l1}')\n",
    "            else:\n",
    "                l1= l0+len(dtArg[sK])+1\n",
    "                # print (f'{type(dtArg[sK])} {sK} at {l0}-{l1}')\n",
    "            l1= min(l1, iL)\n",
    "            dtFound[sK]= [l0, l1]\n",
    "            l0= l1\n",
    "        else:\n",
    "            l0+= 1\n",
    "\n",
    "    # print ('lArg: ', lArg)\n",
    "    # print ('Locations found:', dtFound)\n",
    "\n",
    "    # Read out the arguments\n",
    "    # sK= 'a'\n",
    "    ir= 0\n",
    "    for sK in asK:\n",
    "        bFound= (sK in dtFound)\n",
    "        # print ('key %s, found= %i, arg=' % (sK, bFound), dtArg[sK])\n",
    "        if (isinstance(dtArg[sK], bool)):\n",
    "            dtArg[sK]= bFound\n",
    "            ir+= 1\n",
    "        elif ((isinstance(dtArg[sK], (list, np.ndarray))) and bFound):\n",
    "            vLU= dtFound[sK]\n",
    "            vOrg= dtArg[sK]\n",
    "            vAns= lArg[vLU[0]+1:vLU[1]]\n",
    "            bFloat= (len(vOrg) > 0) and isinstance(vOrg[0], float)\n",
    "            bInt= (len(vOrg) > 0) and isinstance(vOrg[0], int)\n",
    "            dtArg[sK]= ReadArg_float(vAns) if bFloat else ReadArg_int(vAns) if bInt else vAns\n",
    "            ir+= 1\n",
    "        elif (isinstance(dtArg[sK], str) and bFound):\n",
    "            vLU= dtFound[sK]\n",
    "            vAns= lArg[vLU[0]+1:vLU[1]]\n",
    "            dtArg[sK]= vAns[0].strip('\"') if (len(vAns)) else ''\n",
    "            ir+= 1\n",
    "        elif (isinstance(dtArg[sK], (float, int)) and bFound):\n",
    "            vLU= dtFound[sK]\n",
    "            vAns= lArg[vLU[0]+1:vLU[1]]\n",
    "            dtArg[sK]= ReadArg_float(vAns[0:1])[0] if (len(vAns)) else None\n",
    "            ir+= 1\n",
    "        elif (bFound):\n",
    "            print ('Key %s found, but I do not know what to do with it' % sK)\n",
    "        # else:\n",
    "        #     print ('Key %s not found, so not changed' % sK)\n",
    "\n",
    "    if (show):\n",
    "        print('ReadArg encountered arguments:')\n",
    "        for sK in dtArg:\n",
    "            print ('Key %s(reset=%i):' % (sK, sK in dtFound), dtArg[sK])\n",
    "\n",
    "    return ir\n",
    "\n",
    "\n",
    "###########################################################\n",
    "### main()\n",
    "def test():\n",
    "    sArg= 'symbol fsd fsd thisfile'\n",
    "    sArg= 'storeprices symbol fsdb fsd thisfile'\n",
    "    dtArg= {'symbol': 'all',\n",
    "            'fsd': 'otherfile',\n",
    "            'storeprices': True}\n",
    "\n",
    "    argv= sArg.split(' ')\n",
    "    ir= ReadArg_dict(dtArg, show= True, argv= argv )\n",
    "\n",
    "###########################################################\n",
    "### main()\n",
    "def main():\n",
    "    # Magic numbers\n",
    "    dA= 1000\n",
    "    vB= [-1, -1, -1]\n",
    "    sS= 'this is the default'\n",
    "    tS= ['t1', 't2']\n",
    "\n",
    "    dtArg= {'a': dA, 'b': vB, 's': sS, 't': tS}\n",
    "\n",
    "    # dtArg['args']= 'a 5.0 b 1 2 3 s hallo t abc def'\n",
    "\n",
    "    # Initialisation\n",
    "    print ('Usage:\\n  ipython readarg.py a 5.0 b 1 2 3 s hallo t abc def')\n",
    "    print ('This would read a scalar a, vector b of (max) 3 elements, string s, and list of strings t.')\n",
    "    print ('If arguments are not found, default values are filled in, if given')\n",
    "\n",
    "    dA= ReadArg('a', 1)            # No default value\n",
    "    vB= ReadArg('b', 3, vB)\n",
    "    sS= ReadArg('s', -1, sS)\n",
    "    tS= ReadArg('t', -2, tS)\n",
    "\n",
    "    # Output\n",
    "    print (f'A= {dA}', dA)\n",
    "    print ('B=\\n', vB)\n",
    "    print (f's= {sS}', sS)\n",
    "    print ('t= ', tS)\n",
    "\n",
    "    ir= ReadArg(dtArg, show= True)\n",
    "    print ('Using a dictionary: Found %i items, with values \\n' % ir, dtArg)\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "### start main\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22cba3",
   "metadata": {},
   "source": [
    "## libgas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "libGAS.py\n",
    "\n",
    "Purpose:\n",
    "    Estimate data from a gas(1,1) model\n",
    "\n",
    "Version:\n",
    "    1       First start, following simgas.py\n",
    "    2       Copy from models/gas/gas.py, adapted for GARCH and use with qfrm\n",
    "\n",
    "Note:\n",
    "    The GAS(1,1) corresponds to the GARCH(1,1), with a slight change of parameters.\n",
    "\n",
    "    If we have\n",
    "        GARCH:\n",
    "          S2(t+1)= omega + alpha a(t)^2 + beta S2(t)\n",
    "        GAS:\n",
    "          S2(t+1)= O + A s(t) + B S2(t)\n",
    "    with s(t) the score in the GAS filter, then we have correspondence if\n",
    "      O = omega\n",
    "      A = alpha\n",
    "      B = alpha + beta\n",
    "\n",
    "Date:\n",
    "    2019/6/21\n",
    "\n",
    "Author:\n",
    "    Charles Bos\n",
    "\"\"\"\n",
    "###########################################################\n",
    "### (vY, vS2)= GenrGAS(vP, iT)\n",
    "def InitialiseGAS(dtArg):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Initialise settings, prepare data\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 3, with dO, dA, dB\n",
    "        iT      integer, number of observations\n",
    "\n",
    "    Return value:\n",
    "        vY      iT vector, observations\n",
    "        vS2     iT vector, variances\n",
    "    \"\"\"\n",
    "    ReadArg(dtArg)\n",
    "\n",
    "    np.random.seed(dtArg['seed'])\n",
    "\n",
    "    vP0= dtArg['p0']\n",
    "    iT= dtArg['t']\n",
    "    (vY, vS20)= GenrGAS(vP0, iT)\n",
    "    vS2= np.zeros(iT)\n",
    "    FiltGAS(vS2, vY, vP0)\n",
    "    print ('Are they again equal?', np.all(vS2 == vS20))\n",
    "\n",
    "    vL= np.exp(vY/100).cumsum()\n",
    "    dtD1= dt.datetime.today().date()\n",
    "    vD= pd.date_range(dtD1- dt.timedelta(days= iT-1), dtD1)\n",
    "\n",
    "    df= pd.DataFrame(vL, columns= ['y'], index= vD)\n",
    "    df['Return']= vY\n",
    "    df['s20']= vS20\n",
    "\n",
    "    # dtArg['in']= 'data/sim_' + str(df.index[0].year) + '_' + str(df.index[-1].year) \n",
    "\n",
    "    if (len(dtArg['d1'])):\n",
    "        vI= df.index >= dtArg['d1']\n",
    "        if (vI.sum() > 100):\n",
    "            df= df[vI]\n",
    "\n",
    "    dtArg['data']= df\n",
    "    dtArg['y']= df['Return'].dropna().values\n",
    "    dtArg['t']= pd.to_datetime(df['Return'].dropna().index)\n",
    "\n",
    "    # sBase= os.path.basename(dtArg['in'])\n",
    "    # sSt= sBase.split('_')[0]\n",
    "\n",
    "    # iY0= dtArg['t'][0].year\n",
    "    # iY1= dtArg['t'][-1].year\n",
    "    # dtArg['out']= f'graphs/{sSt}_{iY0}_{iY1}_vol.png'\n",
    "\n",
    "    return dtArg['y']\n",
    "\n",
    "###########################################################\n",
    "### (vY, vS2)= GenrGAS(vP, iT)\n",
    "def GenrGAS(vP, iT):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Generate GAS(1,1) data\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 3, with dO, dA, dB\n",
    "        iT      integer, number of observations\n",
    "\n",
    "    Return value:\n",
    "        vY      iT vector, observations\n",
    "        vS2     iT vector, variances\n",
    "    \"\"\"\n",
    "    (dO, dA, dB)= (vP[0], vP[1], vP[2])\n",
    "    vY= np.zeros(iT)\n",
    "    vS2= np.zeros_like(vY)\n",
    "    dF= dO/(1-dB)\n",
    "    for i in range(iT):\n",
    "        vY[i]= np.sqrt(dF) * np.random.randn()\n",
    "        vS2[i]= dF\n",
    "        dF= dO + dA*(vY[i]**2 - dF) + dB*dF\n",
    "\n",
    "    return (vY, vS2)\n",
    "\n",
    "###########################################################\n",
    "### vPTr= TransPar(vP)\n",
    "def TransPar(vP):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Transform the parameters for restrictions\n",
    "\n",
    "    Inputs:\n",
    "      vP        array of size 3, with parameters O, A, B\n",
    "\n",
    "    Return value:\n",
    "      vPTr      array of size 3, with transformed O, A, B\n",
    "    \"\"\"\n",
    "    vPTr= np.copy(vP)\n",
    "    vPTr[0]= np.log(vP[0])\n",
    "    vPTr[1:]= np.log(vP[1:]/(1-vP[1:]))\n",
    "\n",
    "    return vPTr\n",
    "\n",
    "###########################################################\n",
    "### vP= TransBackPar(vPTr)\n",
    "def TransBackPar(vPTr):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Transform the parameters back from restrictions\n",
    "\n",
    "    Inputs:\n",
    "      vPTr      array of size 3, with transformed O, A, B\n",
    "\n",
    "    Return value:\n",
    "      vP        array of size 3, with parameters O, A, B\n",
    "    \"\"\"\n",
    "    vP= np.copy(vPTr)\n",
    "    vP[0]= np.exp(vPTr[0])\n",
    "    vP[1:]= np.exp(vPTr[1:])/(1+np.exp(vPTr[1:]))\n",
    "\n",
    "    return vP\n",
    "\n",
    "###########################################################\n",
    "### vPTr= TransPar(vP)\n",
    "def TransParL(dL):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Transform the parameters for restrictions\n",
    "\n",
    "    Inputs:\n",
    "      dLambda   double\n",
    "\n",
    "    Return value:\n",
    "      dLTr      double, transformed Lambda\n",
    "    \"\"\"\n",
    "    dLTr= np.log(dL/(1-dL))\n",
    "\n",
    "    return dLTr\n",
    "\n",
    "###########################################################\n",
    "### vP= TransBackPar(vPTr)\n",
    "def TransBackParL(dLTr):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Transform the lambda parameters back from restrictions\n",
    "\n",
    "    Inputs:\n",
    "      dLTr      double, transformed Lambda\n",
    "\n",
    "    Return value:\n",
    "      dLambda   double\n",
    "    \"\"\"\n",
    "    dL= np.exp(dLTr)/(1+np.exp(dLTr))\n",
    "\n",
    "    return dL\n",
    "\n",
    "###########################################################\n",
    "### br= FiltGAS(vS2, vY, vP)\n",
    "def FiltGAS(vS2, vY, vP):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Filter the process using the GAS equations\n",
    "\n",
    "    Inputs:\n",
    "        vY      iT vector, observations\n",
    "        vP      vector of size 3, with dO, dA, dB\n",
    "        vS2     iT vector, empty space\n",
    "\n",
    "    Outputs:\n",
    "        vS2     iT vector, variances\n",
    "\n",
    "    Return value:\n",
    "        br      boolean, True if all went well\n",
    "    \"\"\"\n",
    "    iT= vY.shape[0]\n",
    "    (dO, dA, dB)= (vP[0], vP[1], vP[2])\n",
    "\n",
    "    dF= dO/(1-dB)\n",
    "    for i in range(iT):\n",
    "        vS2[i]= dF\n",
    "\n",
    "        # ### Check\n",
    "        # dNabla= -0.5*(1-(vY[i])**2/dF)/dF;\n",
    "        # dI= 0.5/(dF**2)\n",
    "        #\n",
    "        # dS= 1.0 / dI\n",
    "        # ds= dS * dNabla\n",
    "        # if (np.fabs(ds - ((vY[i])**2 - dF)) > 1e-5):\n",
    "        #     print ('i=%i s= %g, salt= %g: ', i, ds, ((vY[i]**2) - dF))\n",
    "\n",
    "        ds= (vY[i])**2 - dF\n",
    "        dF= dO + dA * ds + dB * dF\n",
    "\n",
    "    return not np.any(np.isnan(vS2))\n",
    "\n",
    "###########################################################\n",
    "### vLL= LnLGAS(vP, vY)\n",
    "def LnLGAS(vP, vY):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate vector of LL using the GAS equations\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 3, with dO, dA, dB\n",
    "        vY      iT vector, observations\n",
    "\n",
    "\n",
    "    Return value:\n",
    "        vLL     iT vector, loglikelihoods\n",
    "    \"\"\"\n",
    "    iT= vY.shape[0]\n",
    "    vS2= np.zeros_like(vY)\n",
    "\n",
    "    br= FiltGAS(vS2, vY, vP)\n",
    "    vLL= st.norm.logpdf(vY/np.sqrt(vS2)) - 0.5*np.log(vS2)\n",
    "\n",
    "    # vLL0= -0.5*(np.log(2*np.pi) + np.log(vS2) + (vY**2)/vS2)\n",
    "    # dDiff= np.max(np.abs(vLL - vLL0))\n",
    "    # print ('ll= %g, diff=%g, o=%g, a=%g, b=%g' % (vLL.mean(), dDiff, vP[0], vP[1], vP[2]))\n",
    "    # print ('ll= %g, o=%g, a=%g, b=%g' % (vLL.mean(), vP[0], vP[1], vP[2]))\n",
    "\n",
    "    # vPTr= TransPar(vP)\n",
    "    # print (f'vP: {vP}, ll: {vLL.sum()}')\n",
    "\n",
    "    return vLL\n",
    "\n",
    "###########################################################\n",
    "### (dLL, vS2, sMess)= EstGAS(vP, vY)\n",
    "def EstGAS(vP, vY):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Optimise GAS model\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 3, with dO, dA, dB, starting values\n",
    "        vY      iT vector, observations\n",
    "\n",
    "    Outputs:\n",
    "        vP      3-vector, optimised parameters\n",
    "\n",
    "    Return value:\n",
    "        dLL     double, optimal loglikelihood\n",
    "        vS2     iT vector, time varying variance\n",
    "        sMess   string, message on convergence\n",
    "    \"\"\"\n",
    "    iT= vY.shape[0]\n",
    "    vS2= np.zeros(iT)\n",
    "\n",
    "    # Create function returning NEGATIVE average LL, as function of vP\n",
    "    AvgNLnLGAS= lambda vP: -(LnLGAS(vP, vY).mean())\n",
    "\n",
    "    vP0= np.copy(vP)\n",
    "    print ('In EstGAS')\n",
    "    res= opt.minimize(AvgNLnLGAS, vP0, method='BFGS')\n",
    "\n",
    "    vP[:]= res.x\n",
    "    sMess= res.message\n",
    "    dLL= -iT*res.fun\n",
    "\n",
    "    # print ('\\nBFGS results in ', sMess, '\\nPars: ', vP, '\\nLL= ', dLL, ', f-eval= ', res.nfev)\n",
    "\n",
    "    return (dLL, vS2, sMess)\n",
    "\n",
    "###########################################################\n",
    "### (dLL, vS2, sMess)= EstGAS(vP, vY)\n",
    "def EstGASTr(vP, vY):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Optimise GAS model, using transformation\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 3, with dO, dA, dB, starting values\n",
    "        vY      iT vector, observations\n",
    "\n",
    "    Outputs:\n",
    "        vP      3-vector, optimised parameters\n",
    "\n",
    "    Return value:\n",
    "        dLL     double, optimal loglikelihood\n",
    "        vS2     iT vector, time varying variance\n",
    "        sMess   string, message on convergence\n",
    "    \"\"\"\n",
    "    iT= vY.shape[0]\n",
    "    print ('Hallo')\n",
    "\n",
    "    # Create function returning NEGATIVE average LL, as function of vP\n",
    "    AvgNLnLGASTr= lambda vPTr: -(LnLGAS(TransBackPar(vPTr), vY).mean())\n",
    "\n",
    "    vPTr= TransPar(vP)\n",
    "    dLL= -iT*AvgNLnLGASTr(vPTr)\n",
    "    print ('Initial LL=%g in EstGASTr' % dLL)\n",
    "\n",
    "    res= opt.minimize(AvgNLnLGASTr, vPTr, method='BFGS')\n",
    "\n",
    "    vP[:]= TransBackPar(res.x)\n",
    "    sMess= res.message\n",
    "    dLL= -iT*res.fun\n",
    "    vS2= np.zeros(iT)\n",
    "    FiltGAS(vS2, vY, vP)\n",
    "\n",
    "    # print ('\\nBFGS results in ', sMess, '\\nPars: ', vP, '\\nLL= ', dLL, ', f-eval= ', res.nfev)\n",
    "    # print(vS2)\n",
    "\n",
    "    return (dLL, vS2, sMess)\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "### br= FiltEWMA(vY, dLambda)\n",
    "def FiltEWMA(vY, dLambda, s20= None):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Apply EWMA filter of variance\n",
    "\n",
    "    Inputs:\n",
    "        vY          iT vector, observations\n",
    "        dLambda     double, value for weight\n",
    "        s20         (optional, default is overall variance) double, initial variance\n",
    "\n",
    "    Return value:\n",
    "        vS2     iT vector, time varying variance\n",
    "    \"\"\"\n",
    "    # dLambda= 0.8\n",
    "    s20= s20 or np.var(vY)\n",
    "\n",
    "    iT= len(vY)\n",
    "    vS2= np.zeros_like(vY)\n",
    "    vS2[0]= s20\n",
    "    for i in range(0, iT):\n",
    "        vS2[i]= s20\n",
    "        s20= dLambda * s20 + (1-dLambda)*(vY[i]**2)\n",
    "\n",
    "    return vS2\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "### dD2= AvgEWMAdist(vY, dLambda)\n",
    "def AvgEWMAdist(vY, dLambda, s20= None):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate average misfit of EWMA filter of variance\n",
    "\n",
    "    Inputs:\n",
    "        vY          iT vector, observations\n",
    "        dLambda     double, value for weight\n",
    "\n",
    "    Return value:\n",
    "        dD2         double, average difference between vY^2 and vS2\n",
    "    \"\"\"\n",
    "    iT= len(vY)\n",
    "    vS2= FiltEWMA(vY, dLambda, s20= s20)\n",
    "\n",
    "    vD= (vY**2) - vS2\n",
    "    dD2= np.mean(vD**2)\n",
    "\n",
    "    print (f'l {dLambda}, s20= {s20}, d= {dD2}')\n",
    "\n",
    "    return dD2\n",
    "\n",
    "###########################################################\n",
    "### main\n",
    "def EstEWMATr(vLambda, vY):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Estimate an EWMA filter of variance\n",
    "\n",
    "    Inputs:\n",
    "        vY          iT vector, observations\n",
    "        dLambda0    (optional, default= 0.8) initial value for weight\n",
    "\n",
    "    Return value:\n",
    "        dLambda double, optimal weight\n",
    "        vS2     iT vector, time varying variance\n",
    "    \"\"\"\n",
    "    iT= len(vY)\n",
    "\n",
    "    # Create function returning average distance to minimize\n",
    "    AvgEWMAdistLTr= lambda vLTr: np.mean((vY**2 - FiltEWMA(vY, TransBackParL(vLTr)[0]))**2)\n",
    "    # AvgEWMAdistLTr= lambda vLTr: AvgEWMAdist(vY, TransBackParL(vLTr)[0])\n",
    "\n",
    "    dLambda0= vLambda[0]\n",
    "    vLTr= np.array([TransParL(dLambda0)])\n",
    "\n",
    "    dD= iT*AvgEWMAdistLTr(vLTr)\n",
    "    print (f'Initial D={dD}')\n",
    "\n",
    "    res= opt.minimize(AvgEWMAdistLTr, vLTr, method='BFGS')\n",
    "    dLambda= TransBackParL(res.x)[0]\n",
    "    sMess= res.message\n",
    "    dD= iT*res.fun\n",
    "\n",
    "    vS2= FiltEWMA(vY, dLambda)\n",
    "    vLambda[0]= dLambda\n",
    "\n",
    "    print ('\\nBFGS results in ', sMess, '\\nPars: ', dLambda, '\\nD= ', dD, ', f-eval= ', res.nfev)\n",
    "\n",
    "    return (dD, vS2, sMess)\n",
    "\n",
    "\n",
    "###########################################################\n",
    "### main\n",
    "def main():\n",
    "    # Magic numbers\n",
    "    dtArg= {\n",
    "             'd1': '05/01/2012',\n",
    "             't': 1000,\n",
    "             'seed': 1234,\n",
    "             'p0': [.1, .05, .95],\n",
    "             'l0': .8,\n",
    "             'lRM': .94,\n",
    "           }\n",
    "\n",
    "    # Initialisation\n",
    "    vP0= dtArg['p0']\n",
    "    vY= InitialiseGAS(dtArg)\n",
    "    vT= dtArg['t']\n",
    "    # sOut= dtArg['out']\n",
    "\n",
    "    # # Estimation\n",
    "    # vP= np.copy(vP0)\n",
    "    # (dLL, vS2, sMess) = EstGAS(vP, vY)\n",
    "\n",
    "    vP= np.copy(vP0)\n",
    "    (dLL, vS2, sMess)= EstGASTr(vP, vY)\n",
    "\n",
    "    vL0= np.array([dtArg['l0']])\n",
    "    (dD, vS2e, sMesse)= EstEWMATr(vL0, vY)\n",
    "    vS2rm= FiltEWMA(vY, dtArg['lRM'])\n",
    "\n",
    "    # Output\n",
    "\n",
    "    plt.figure(figsize= (8, 4))\n",
    "    ax= plt.subplot(1, 2, 1)\n",
    "    plt.plot(vT, vY, 'b.', label='y')\n",
    "    if ('s20' in dtArg):\n",
    "        plt.plot(vT, -np.sqrt(dtArg['s20']), 'g-', label='Generated sdev')\n",
    "    plt.plot(vT, 2*np.sqrt(vS2), 'r-', label='Volatility GARCH')\n",
    "    plt.plot(vT, 2*np.sqrt(vS2e), 'g-', label=f'Volatility EWMA(l={vL0[0]:.2f})')\n",
    "    plt.plot(vT, 2*np.sqrt(vS2rm), 'y-', label=f'Volatility EWMA(lRM={dtArg[\"lRM\"]})')\n",
    "\n",
    "    plt.plot(vT, -2*np.sqrt(vS2), 'r-')\n",
    "    plt.plot(vT, -2*np.sqrt(vS2e), 'g-')\n",
    "    plt.plot(vT, -2*np.sqrt(vS2rm), 'y-')\n",
    "\n",
    "    fmTime = mdates.DateFormatter('%y')\n",
    "    ax.xaxis.set_major_formatter(fmTime)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    ax= plt.subplot(1, 2, 2)\n",
    "    plt.plot(vT, np.sqrt(vS2), 'r-', label='Volatility GARCH')\n",
    "    plt.plot(vT, np.sqrt(vS2e), 'g-', label=f'Volatility EWMA(l={vL0[0]:.2f})')\n",
    "    plt.plot(vT, np.sqrt(vS2rm), 'y-', label=f'Volatility EWMA(lRM={dtArg[\"lRM\"]})')\n",
    "    ax.xaxis.set_major_formatter(fmTime)\n",
    "\n",
    "    # plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "###########################################################\n",
    "### start main\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81ba94",
   "metadata": {},
   "source": [
    "## estcop4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eea404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "EstCOP.py\n",
    "\n",
    "Purpose:\n",
    "    Estimate copula\n",
    "\n",
    "Version:\n",
    "    1       First start, based on l2/estgas.py\n",
    "    2       Include Gumbel/Clayton copula estimation\n",
    "    3       Trying to get Gumbel working right...\n",
    "    4       Cleaning out checking code\n",
    "\n",
    "Note:\n",
    "    The GAS(1,1) corresponds to the GARCH(1,1), with a slight change of parameters.\n",
    "\n",
    "    If we have\n",
    "        GARCH:\n",
    "          S2(t+1)= omega + alpha a(t)^2 + beta S2(t)\n",
    "        GAS:\n",
    "          S2(t+1)= O + A s(t) + B S2(t)\n",
    "    with s(t) the score in the GAS filter, then we have correspondence if\n",
    "      O = omega\n",
    "      A = alpha\n",
    "      B = alpha + beta\n",
    "\n",
    "Date:\n",
    "    2019/6/21, 2025/3/20\n",
    "\n",
    "Author:\n",
    "    Charles Bos\n",
    "\"\"\"\n",
    "###########################################################\n",
    "### (vY, vS2)= GenrGAS(vP, iT)\n",
    "def Initialise(dtArg):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Initialise settings, prepare data\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 3, with dO, dA, dB\n",
    "        iT      integer, number of observations\n",
    "\n",
    "    Return value:\n",
    "        vY      iT vector, observations\n",
    "        vS2     iT vector, variances\n",
    "    \"\"\"    \n",
    "    #ReadArg(dtArg)\n",
    "\n",
    "    # assume dtArg already exists and ReadArg(dtArg) has been called if needed\n",
    "\n",
    "    df = df_pair2.copy()\n",
    "    df = df.dropna()\n",
    "    dtArg['data.df'] = df\n",
    "    cols = df.columns.tolist()\n",
    "    dtArg['vars'] = cols\n",
    "    dtArg['tickers'] = [c.replace('C_', '') for c in cols]\n",
    "    dtArg['y'] = df[ cols ].values\n",
    "    dtArg['t'] = df.index.to_numpy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def EstimMargin(dtArg):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Estimate GARCH-Normal margins on the variables of interest\n",
    "\n",
    "    Inputs:\n",
    "        dtArg   dictionary, settings with df_pair1, vars\n",
    "\n",
    "    Outputs:\n",
    "        dtArg   dictionary, with res.df with parameter estimates, and df_pair1 updated with S2 and U\n",
    "    \"\"\"\n",
    "    vP0= dtArg['p0']\n",
    "    df= dtArg['data.df']\n",
    "    avP= []\n",
    "    for r in dtArg['vars']:\n",
    "        vP= np.copy(vP0)\n",
    "        vY= df[r].values\n",
    "        dM= vY.mean()\n",
    "        print (f'\\n=====\\nEstimating model for \"{r}\"')\n",
    "        (dLL, vS2, sMess)= EstGASTr(vP, vY-dM)\n",
    "        df[ 'S2' + r[1:]]= vS2\n",
    "        vU= st.norm.cdf((vY-dM) / np.sqrt(vS2))\n",
    "        df[ 'U' + r[1:]]= vU\n",
    "\n",
    "        avP.append(vP)\n",
    "    dtArg['res.df']= pd.DataFrame(avP, index= dtArg['vars'], columns= ['O', 'A', 'B'])\n",
    "\n",
    "###########################################################\n",
    "### main\n",
    "def DisplayDF(dtArg):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Display the output of the margin estimation\n",
    "    \"\"\"\n",
    "    df      = dtArg['data.df']\n",
    "    vars_   = dtArg['vars']     # ['C_Volkswagen','C_Stellantis']\n",
    "    tickers = dtArg['tickers']  # ['Volkswagen','Stellantis']\n",
    "\n",
    "    # U-columns were created as 'U_' + original var names\n",
    "    U_vars = ['U' + v[1:] for v in vars_]  # drops the leading 'C'\n",
    "\n",
    "\n",
    "    # Date formatter\n",
    "    fmTime = mdates.DateFormatter('%y')\n",
    "\n",
    "    # 1) Plot the raw returns\n",
    "    plt.figure(figsize=(8,4))\n",
    "    ax = plt.subplot(2,3,1)\n",
    "    ax.plot(df[vars_])                       # use the true column names\n",
    "    ax.legend(tickers)                       # label with the simpler tickers\n",
    "    ax.xaxis.set_major_formatter(fmTime)\n",
    "\n",
    "    # 2) Scatter of U columns\n",
    "    ax = plt.subplot(2,3,4)\n",
    "    ax.plot(df[U_vars[0]], df[U_vars[1]], '.', label='U(GARCH)')\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(fmTime)\n",
    "\n",
    "    # 3) For each asset: plot returns ±2σ\n",
    "    for i, var in enumerate(vars_):\n",
    "        ax = plt.subplot(2,3,2 + 3*i)\n",
    "        # var is 'C_Volkswagen', so 'S2' + var[1:] becomes 'S2_Volkswagen'\n",
    "        ax.plot(df[var], '.', label=tickers[i])\n",
    "        ax.plot(2*np.sqrt(df['S2' + var[1:]]), 'r-')\n",
    "        ax.plot(-2*np.sqrt(df['S2' + var[1:]]), 'r-')\n",
    "        ax.legend()\n",
    "        ax.xaxis.set_major_formatter(fmTime)\n",
    "\n",
    "    # 4) For each asset: plot U over time\n",
    "    for i, Uvar in enumerate(U_vars):\n",
    "        ax = plt.subplot(2,3,3 + 3*i)\n",
    "        ax.plot(df[Uvar], '.', label=tickers[i])\n",
    "        ax.legend()\n",
    "        ax.xaxis.set_major_formatter(fmTime)\n",
    "\n",
    "    # 5) Save first figure\n",
    "    # inp = dtArg.get('in', 'copula_output')\n",
    "    # sOut = inp.replace('data','graphs').replace('.csv.gz','cop.png')\n",
    "    # plt.savefig(sOut)\n",
    "    plt.show()\n",
    "\n",
    "    # 6) Final scatter of U vs U\n",
    "    plt.figure(figsize=(6,6))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(df[U_vars[0]], df[U_vars[1]], '.')\n",
    "    ax.set_xlabel(tickers[0])\n",
    "    ax.set_ylabel(tickers[1])\n",
    "    # sOut2 = inp.replace('data','graphs').replace('.csv.gz','copu.png')\n",
    "    # plt.savefig(sOut2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "###########################################################\n",
    "###vPTr= TransPar(vP, mod= 'gauss')\n",
    "def TransParC(vP, mod= 'gauss'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Transform the parameters for restrictions\n",
    "\n",
    "    Inputs:\n",
    "      vP        array of size 1 or 2, with parameters rho and nu, or theta\n",
    "\n",
    "    Return value:\n",
    "      vPTr      array, with transformed rho and nu, or theta\n",
    "    \"\"\"\n",
    "    vPTr= np.copy(vP)\n",
    "    if (mod in ['gauss', 'stud']):\n",
    "        vPTr[0]= np.log(vP[0]/(1-vP[0]))\n",
    "        if (len(vPTr) > 1):\n",
    "            vPTr[1]= np.log(vP[1]-2)\n",
    "    else:\n",
    "        dLim= -1 if mod.startswith('clayton') else 1\n",
    "        vPTr[0]= np.log(vPTr[0] - dLim)\n",
    "\n",
    "    return vPTr\n",
    "\n",
    "###########################################################\n",
    "###vP= TransBackPar(vPTr)\n",
    "def TransBackParC(vPTr, mod= 'gauss'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "      Transform the parameters back from restrictions\n",
    "\n",
    "    Inputs:\n",
    "      vPTr      array, with transformed rho and nu, or theta\n",
    "\n",
    "    Return value:\n",
    "      vP        array of size 1 or 2, with parameters rho and nu, or theta\n",
    "    \"\"\"\n",
    "    vP= np.copy(vPTr)\n",
    "    if (mod in ['gauss', 'stud']):\n",
    "        vP[0]= np.exp(vPTr[0])/(1+np.exp(vPTr[0]))\n",
    "        if (len(vP) > 1):\n",
    "            vP[1]= 2+np.exp(vPTr[1])\n",
    "    else:\n",
    "        dLim= -1 if mod.startswith('clayton') else 1\n",
    "        vP[0]= dLim+np.exp(vPTr[0])\n",
    "\n",
    "    return vP\n",
    "\n",
    "###########################################################\n",
    "### vLL= LnLCopExpl(vP, mU, mod= 'clayton')\n",
    "def LnLCopExplSM(vP, mU, mod= 'gumbelSM'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate the loglikelihood according to the explicit copula density, through statsmodels\n",
    "    \"\"\"\n",
    "    # vP= TransBackParC(vPTr, mod= mod)\n",
    "    iT= mU.shape[0]\n",
    "    dTheta= vP[0]\n",
    "\n",
    "    if (mod == 'gumbelSM'):\n",
    "        copula= GumbelCopula(theta= dTheta)\n",
    "    else:\n",
    "        copula= ClaytonCopula(theta= dTheta)\n",
    "    vLL= copula.logpdf(mU)\n",
    "\n",
    "    return vLL\n",
    "\n",
    "###########################################################\n",
    "### vLL= LnLCopExpl(vP, mU, mod= 'clayton')\n",
    "def LnLCopExpl(vP, mU, mod= 'gumbel'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate the loglikelihood according to the explicit copula density\n",
    "    \"\"\"\n",
    "    # vP= TransBackParC(vPTr, mod= mod)\n",
    "    iT= mU.shape[0]\n",
    "    dTheta= vP[0]\n",
    "    if (mod == 'gumbel'):\n",
    "        # Generator\n",
    "        fnPsi= lambda t: np.exp(-t**(1/dTheta))\n",
    "        # First derivative of generator\n",
    "        fnpsi= lambda t: -t**(1/dTheta-1) * fnPsi(t) / dTheta\n",
    "        # Second derivative of generator\n",
    "        fnpsi2= lambda t: t**(1/dTheta-2) * (-1 + dTheta + t**(1/dTheta)) * fnPsi(t) / dTheta**2\n",
    "\n",
    "        # Inverse generator x(u)\n",
    "        fnPsiI= lambda u: (-np.log(u))**dTheta\n",
    "        # First derivative of inverse generator x(u)\n",
    "        fnpsiI= lambda u: -dTheta*(-np.log(u))**(dTheta-1) / u\n",
    "    elif (mod == 'clayton'):\n",
    "        # Generator\n",
    "        fnPsi= lambda t: (1+dTheta*t)**(-1/dTheta)\n",
    "        # First derivative of generator\n",
    "        fnpsi= lambda t: -(1+dTheta*t)**(-1/dTheta-1)\n",
    "        # Second derivative of generator\n",
    "        fnpsi2= lambda t: (1+dTheta)*(1+dTheta*t)**(-1/dTheta-2)\n",
    "\n",
    "        # Inverse generator x(u)\n",
    "        fnPsiI= lambda u: (u**(-dTheta) - 1)/dTheta\n",
    "        # First derivative of inverse generator x(u)\n",
    "        fnpsiI= lambda u: -u**(-dTheta-1)\n",
    "    else:\n",
    "        print (f'Error: Model {mod} not recognised')\n",
    "        return np.nan\n",
    "\n",
    "    # Get the loglikelihood\n",
    "    mX= fnPsiI(mU)\n",
    "    vX= mX.sum(axis= 1)\n",
    "    vL= fnpsi2(vX)*fnpsiI(mU).prod(axis= 1)\n",
    "\n",
    "    vLL= np.log(vL)\n",
    "\n",
    "    print (f'l: {vLL.sum():.4f}, th: {dTheta:.4f}')\n",
    "    if (len(vLL) != iT):\n",
    "        print (f'Error: shape of vLL= {vLL.shape}, should be ({iT},)')\n",
    "\n",
    "    return vLL\n",
    "\n",
    "###########################################################\n",
    "### vLL= LnLCopImpl(vP, mU, mod= 'stud')\n",
    "def LnLCopImpl(vP, mU, mod= 'gauss'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate vector of LL using the Copula equations\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 1 or 2, with dRho, dNu\n",
    "        mU      iT x 2 matrix, observations\n",
    "\n",
    "\n",
    "    Return value:\n",
    "        vLL     iT vector, loglikelihoods\n",
    "    \"\"\"\n",
    "    if (mod == 'gauss'):\n",
    "        dNu= np.inf\n",
    "        fnf= st.norm()\n",
    "    elif (mod == 'stud'):\n",
    "        dNu= vP[1]\n",
    "        fnf= st.t(dNu)\n",
    "    else:\n",
    "        print (f'Error: Model {mod} not recognised')\n",
    "        return np.nan\n",
    "\n",
    "    iT= mU.shape[0]\n",
    "    dRho= vP[0]\n",
    "    mP= np.array([[1, dRho], [dRho, 1]])\n",
    "    mC= np.linalg.cholesky(mP)\n",
    "    mCi= np.linalg.inv(mC)\n",
    "    (iS, dLogD)= np.linalg.slogdet(mP)\n",
    "\n",
    "    mX= fnf.ppf(mU)\n",
    "    vF= fnf.logpdf(mCi@mX.T).sum(axis= 0) - 0.5*dLogD\n",
    "    vG= fnf.logpdf(mX.T).sum(axis= 0)\n",
    "    vLL= vF - vG\n",
    "\n",
    "    if (len(vLL) != iT):\n",
    "        print (f'Error: shape of vLL= {vLL.shape}, should be ({iT},)')\n",
    "\n",
    "    return vLL\n",
    "\n",
    "###########################################################\n",
    "### vLL= LnLGAS(vP, mU)\n",
    "def LnLCop(vP, mU, mod= 'gauss'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Calculate vector of LL using the Copula equations\n",
    "\n",
    "    Inputs:\n",
    "        vP      vector of size 1 or 2, with dRho, dNu, or theta\n",
    "        mU      iT x 2 matrix, observations\n",
    "\n",
    "    Return value:\n",
    "        vLL     iT vector, loglikelihoods\n",
    "    \"\"\"\n",
    "    if (mod in ['gumbel', 'clayton']):\n",
    "        return LnLCopExpl(vP, mU, mod= mod)\n",
    "    if (mod in ['gumbelSM', 'claytonSM']):\n",
    "        return LnLCopExplSM(vP, mU, mod= mod)\n",
    "    return LnLCopImpl(vP, mU, mod= mod)\n",
    "\n",
    "###########################################################\n",
    "### main\n",
    "def EstCopula(dtArg, mod= 'gauss'):\n",
    "    # mod= 'gumbel'\n",
    "    df= dtArg['data.df']\n",
    "    asTick = dtArg['tickers']\n",
    "    asU = ['U_' + t for t in asTick]\n",
    "    mU = df[asU]\n",
    "\n",
    "\n",
    "    iT= mU.shape[0]\n",
    "\n",
    "    # mR= mU.rank()\n",
    "    mR= mU          # No need to take the ranks, scipy.stats will take those\n",
    "    res= st.kendalltau(mR.iloc[:, 0], mR.iloc[:,1])\n",
    "    dRtau= res.statistic\n",
    "    if (mod in ['gauss', 'stud']):\n",
    "        mP0= mU.corr()\n",
    "        dP0= mP0.iloc[0, 1]\n",
    "        dNu= 4.0\n",
    "    elif (mod.startswith('gumbel')):\n",
    "        dTheta= dP0= 1/(1-dRtau)\n",
    "    else:\n",
    "        res= st.spearmanr(mU)\n",
    "        dRsp= res.statistic\n",
    "        dTheta= dP0= dRsp\n",
    "        dP0= 2.0\n",
    "        dTheta= dP0= 2*dRtau/(1-dRtau)\n",
    "    vP0= np.array([dP0, dNu]) if mod == 'stud' else np.array([dP0])\n",
    "\n",
    "    # Create function returning NEGATIVE average LL, as function of vP\n",
    "    AvgNLnLCopTr= lambda vPTr: -(LnLCop(TransBackParC(vPTr, mod= mod), mU, mod= mod).mean())\n",
    "\n",
    "    vPTr= TransParC(vP0, mod= mod)\n",
    "    dALnL= AvgNLnLCopTr(vPTr)\n",
    "    res= opt.minimize(AvgNLnLCopTr, vPTr, method='BFGS')\n",
    "\n",
    "    vP= TransBackParC(res.x, mod= mod)\n",
    "    sMess= res.message\n",
    "    dLL= -iT*res.fun\n",
    "\n",
    "    print ('\\nBFGS results in ', sMess, '\\nPars: ', vP, '\\nLL= ', dLL, ', f-eval= ', res.nfev)\n",
    "\n",
    "    # LnLCopL= lambda x: -(LnLCop([x], mU, mod= mod).mean())\n",
    "    # vT= np.arange(1, 3, .01)\n",
    "    # vL= [ LnLCopL(t) for t in vT ]\n",
    "    return (dLL, vP, sMess)\n",
    "\n",
    "def plot_copula_contours(dtArg, dfR):\n",
    "    df    = dtArg['data.df']\n",
    "    tickers = dtArg['tickers']\n",
    "    U     = df[['U_' + t for t in tickers]].values\n",
    "    iT    = U.shape[0]\n",
    "\n",
    "    # grid for (u,v)\n",
    "    grid = np.linspace(0.01, 0.99, 50)\n",
    "    U1, U2 = np.meshgrid(grid, grid)\n",
    "    uv = np.column_stack([U1.ravel(), U2.ravel()])\n",
    "\n",
    "    # define models to plot\n",
    "    models = {\n",
    "        'Gumbel':   (GumbelCopula(theta=dfR.loc['Theta','gumbel']),   norm, norm),\n",
    "        'Clayton':  (ClaytonCopula(theta=dfR.loc['Theta','clayton']), norm, norm),\n",
    "    }\n",
    "\n",
    "    for name, (cop, m1, m2) in models.items():\n",
    "        cop_dist = CopulaDistribution(copula=cop,\n",
    "                                      marginals=[m1(), m2()])\n",
    "        Z = cop_dist.pdf(uv).reshape(U1.shape)\n",
    "\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.contour(U1, U2, Z, levels=8)\n",
    "        plt.scatter(U[:,0], U[:,1], s=5, alpha=0.6)\n",
    "        plt.title(f'{name} copula fit')\n",
    "        plt.xlabel('U₁'); plt.ylabel('U₂')\n",
    "    plt.show()\n",
    "\n",
    "def frechet_bounds(u, v):\n",
    "    \"\"\"\n",
    "    Compute the Fréchet–Hoeffding lower (W) and upper (M) bounds\n",
    "    for two arrays of U(0,1) observations.\n",
    "    \"\"\"\n",
    "    u = np.asarray(u)\n",
    "    v = np.asarray(v)\n",
    "    W = np.maximum(u + v - 1, 0.0)\n",
    "    M = np.minimum(u, v)\n",
    "    return W, M\n",
    "\n",
    "###########################################################\n",
    "## main\n",
    "def main():\n",
    "    # ─── 1) Magic numbers ─────────────────────────────────────────────────────\n",
    "    dtArg = {\n",
    "        'd1':  '05/01/2012',\n",
    "        'p0':  [.1, .05, .95],\n",
    "        'l0':  .8,\n",
    "        'lRM': .94,\n",
    "    }\n",
    "\n",
    " # Initialisation\n",
    "    df= Initialise(dtArg)\n",
    "\n",
    "    # Estimation\n",
    "    EstimMargin(dtArg)\n",
    "\n",
    "    asTick= dtArg['tickers']\n",
    "\n",
    "    asU= ['U_' + t for t in asTick]\n",
    "    mU= df[asU]\n",
    "    print(df[asU])\n",
    "    mP0= mU.corr()\n",
    "    dRho0= mP0.iloc[0, 1]\n",
    "\n",
    "    # mR= mU.rank()\n",
    "    mR= mU          # No need to take the ranks, scipy.stats will take those\n",
    "    res= st.kendalltau(mR.iloc[:, 0], mR.iloc[:,1])\n",
    "    dRtau= res.statistic\n",
    "    dThetaGu= 1/(1-dRtau)\n",
    "    dThetaCl= 2*dRtau/(1-dRtau)\n",
    "\n",
    "    dfR= pd.DataFrame(index= ['Rho', 'Nu', 'Theta', 'LL'])\n",
    "    dfR.loc['Rho', 'Corr']= dRho0\n",
    "\n",
    "    (dLLn, vPn, sMessn)= EstCopula(dtArg, mod= 'gauss')\n",
    "    dfR.loc['Rho', 'Norm']= vPn\n",
    "    dfR.loc['LL', 'Norm']= dLLn\n",
    "\n",
    "    (dLLt, vPt, sMesst)= EstCopula(dtArg, mod= 'stud')\n",
    "    dfR.loc[['Rho', 'Nu'], 't']= vPt\n",
    "    dfR.loc['LL', 't']= dLLt\n",
    "\n",
    "    dfR.loc['Theta', 'GuTau']= dThetaGu\n",
    "    (dLLg, vPg, sMessg)= EstCopula(dtArg, mod= 'gumbel')\n",
    "    dfR.loc['Theta', 'gumbel']= vPg\n",
    "    dfR.loc['LL', 'gumbel']= dLLg\n",
    "\n",
    "    (dLLg, vPg, sMessg)= EstCopula(dtArg, mod= 'gumbelSM')\n",
    "    dfR.loc['Theta', 'gumbelSM']= vPg\n",
    "    dfR.loc['LL', 'gumbelSM']= dLLg\n",
    "\n",
    "    dfR.loc['Theta', 'ClTau']= dThetaCl\n",
    "    (dLLc, vPc, sMessc)= EstCopula(dtArg, mod= 'clayton')\n",
    "    dfR.loc['Theta', 'clayton']= vPc\n",
    "    dfR.loc['LL', 'clayton']= dLLc\n",
    "\n",
    "    (dLLc, vPc, sMessc)= EstCopula(dtArg, mod= 'claytonSM')\n",
    "    dfR.loc['Theta', 'claytonSM']= vPc\n",
    "    dfR.loc['LL', 'claytonSM']= dLLc\n",
    "\n",
    "    # Output\n",
    "    DisplayDF(dtArg)\n",
    "\n",
    "    print ('Estimation results:')\n",
    "    print (dfR.iloc[:, :3].dropna(axis= 0, how= 'all').to_latex(float_format= '%.3f'))\n",
    "    print (dfR.iloc[:, 3:].dropna(axis= 0, how= 'all').to_latex(float_format= '%.3f'))\n",
    "\n",
    "###########################################################\n",
    "### start main\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64811608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
